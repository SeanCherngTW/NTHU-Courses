{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akl\n",
    "import math\n",
    "import operator\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "akl = list(akl.akl.keys())\n",
    "PRONS = set([line.strip('\\n') for line in open('prons.txt')])\n",
    "with open('HiFreWords') as f:\n",
    "    HiFreWords = set(f.readline().split('\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_pattern_list(input_pat):\n",
    "    pattern = []\n",
    "    final = []\n",
    "    for i in input_pat:\n",
    "        if i != '':\n",
    "            pattern.append(i)\n",
    "        else:\n",
    "            final.append(pattern.copy())\n",
    "            pattern.clear()\n",
    "\n",
    "    # Last one\n",
    "    final.append(pattern)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus\n",
    "corpus = open('corpus_adj_n3.txt', 'r').read().strip('\\n').split('\\n')\n",
    "corpus = create_sentence_pattern_list(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract patterns from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pattern_dict():\n",
    "    pattern_dict = defaultdict(lambda: defaultdict(list))\n",
    "    example_sentences = defaultdict(lambda: defaultdict(list))\n",
    "    for _object in corpus:\n",
    "        sent = _object[0]\n",
    "        for c in _object[1:]:\n",
    "            term, grammar, pattern = c.split('\\t')\n",
    "            pattern_dict[term][grammar] += [pattern]\n",
    "            example_sentences[term][grammar] += [sent.split()]\n",
    "            \n",
    "    return pattern_dict, example_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_dict, example_sentences = build_pattern_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check extracted patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pattern_dict():\n",
    "    print('ABILITY -N')\n",
    "    print('N to v \\t\\t(pd:%d, label:468)\\n' % len(pattern_dict['ABILITY']['N to v']))\n",
    "    \n",
    "    print('VALUE -N')\n",
    "    print('N to v \\t\\t(pd:%3d, label: 16)\\n' % len(pattern_dict['VALUE']['N to v']))\n",
    "    \n",
    "    print('DISCUSS -V')\n",
    "    print('V in n \\t\\t(pd:%3d, label: 47)' % len(pattern_dict['DISCUSS']['V in n']))\n",
    "    print('V n \\t\\t(pd:%3d, label:270)' % len(pattern_dict['DISCUSS']['V n']))\n",
    "    print('V wh to v \\t(pd:%3d, label: 15)\\n' % len(pattern_dict['DISCUSS']['V wh to v']))\n",
    "    \n",
    "    print('FAVOUR -V')\n",
    "    print('V n \\t\\t(pd:%3d, label: 26)' % len(pattern_dict['FAVOUR']['V n']))\n",
    "    print('V by n \\t\\t(pd:%3d, label:  5)\\n' % len(pattern_dict['FAVOUR']['V by n']))\n",
    "    \n",
    "    print('CLASSIFY -V')\n",
    "    print('V into n \\t(pd:%3d, label:  8)' % len(pattern_dict['CLASSIFY']['V into n']))\n",
    "    print('V as n \\t\\t(pd:%3d, label: 12)\\n' % len(pattern_dict['CLASSIFY']['V as n']))\n",
    "\n",
    "    print('USEFUL -ADJ')\n",
    "    print('ADJ to v \\t(pd:%3d, label: 30)' % len(pattern_dict['USEFUL']['ADJ to v']))\n",
    "    print('ADJ for n \\t(pd:%3d, label: 20)\\n' % len(pattern_dict['USEFUL']['ADJ for n']))\n",
    "    \n",
    "    print('CERTAIN -ADJ')\n",
    "    print('ADJ of n \\t(pd:%3d, label: 23)' % len(pattern_dict['CERTAIN']['ADJ of n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABILITY -N\n",
      "N to v \t\t(pd:468, label:468)\n",
      "\n",
      "VALUE -N\n",
      "N to v \t\t(pd: 16, label: 16)\n",
      "\n",
      "DISCUSS -V\n",
      "V in n \t\t(pd: 57, label: 47)\n",
      "V n \t\t(pd:270, label:270)\n",
      "V wh to v \t(pd: 15, label: 15)\n",
      "\n",
      "FAVOUR -V\n",
      "V n \t\t(pd: 26, label: 26)\n",
      "V by n \t\t(pd:  5, label:  5)\n",
      "\n",
      "CLASSIFY -V\n",
      "V into n \t(pd:  8, label:  8)\n",
      "V as n \t\t(pd: 12, label: 12)\n",
      "\n",
      "USEFUL -ADJ\n",
      "ADJ to v \t(pd: 30, label: 30)\n",
      "ADJ for n \t(pd: 20, label: 20)\n",
      "\n",
      "CERTAIN -ADJ\n",
      "ADJ of n \t(pd: 23, label: 23)\n"
     ]
    }
   ],
   "source": [
    "check_pattern_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeScore(word, sent):\n",
    "    global PRONS\n",
    "    global HiFreWords\n",
    "    \n",
    "    word = word.lower()\n",
    "    sent = sent.lower().split()\n",
    "    length = len(sent)\n",
    "    \n",
    "    locationOfWord = -1 if word not in sent else sent.index(word) \n",
    "    hiFreWordsScore = len([w for w in sent if w not in HiFreWords])\n",
    "    pronsScore = len([w for w in sent if w in PRONS])\n",
    "    \n",
    "    return locationOfWord - hiFreWordsScore - pronsScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_pattern(word):\n",
    "    avg = 0.0\n",
    "    stddev = 0.0\n",
    "    k0 = 1\n",
    "    \n",
    "    word = word.upper()\n",
    "    \n",
    "    print(word)\n",
    "\n",
    "    # Total grammar count for the input word\n",
    "#     N = len(pattern_dict[word].values())\n",
    "    N = 0\n",
    "    \n",
    "#     if N == 0:\n",
    "#         print('NO RESULT\\n')\n",
    "#         return\n",
    "\n",
    "    # Calculate sentence length avg of a grammar\n",
    "    for grammar, sentences in pattern_dict[word].items():\n",
    "        N += len(sentences)\n",
    "        for sentence in example_sentences[word][grammar]:\n",
    "            freqi = len(sentence)\n",
    "            avg += freqi\n",
    "    avg /= N\n",
    "#     print(N)\n",
    "#     print(avg)\n",
    "\n",
    "#     ＃ 算每個句子長度的avg, stddev\n",
    "#     ＃ 再透過條件一去篩選出好的文法與句子\n",
    "#     ＃\n",
    "    # Calculate stddev\n",
    "    for grammar, sentences in pattern_dict[word].items():\n",
    "        for sentence in example_sentences[word][grammar]:\n",
    "            freqi = len(sentence)\n",
    "            stddev += (freqi - avg) ** 2\n",
    "    stddev = math.sqrt(stddev / N)\n",
    "    \n",
    "#     print(stddev)\n",
    "        \n",
    "    if stddev == 0:\n",
    "        print('NO RESULT\\n')\n",
    "        return\n",
    "\n",
    "    best_score = -999.9\n",
    "    best_sentence = ''\n",
    "    \n",
    "    # Filter good grammar\n",
    "    for grammar, sentences in pattern_dict[word].items():\n",
    "        freqi = len(sentences)\n",
    "        strength = (freqi - avg) / stddev\n",
    "        if not strength > k0:\n",
    "            continue\n",
    "\n",
    "        # Find Good Dictionary Example\n",
    "        for sentence in sentences:\n",
    "            score = computeScore(word, sentence)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_sentence = sentence\n",
    "\n",
    "        print('%s (%d) %s' % (grammar, freqi, best_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case():\n",
    "    get_best_pattern('ability')\n",
    "    get_best_pattern('value')\n",
    "    get_best_pattern('discuss')\n",
    "    get_best_pattern('favour')\n",
    "    get_best_pattern('classify')\n",
    "    get_best_pattern('useful')\n",
    "    get_best_pattern('certain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABILITY\n",
      "N to v (468) its bulk and ability to fly\n",
      "\n",
      "VALUE\n",
      "\n",
      "DISCUSS\n",
      "V in n (57) may discuss in person\n",
      "V n (270) concerned may have and discuss them\n",
      "\n",
      "FAVOUR\n",
      "\n",
      "CLASSIFY\n",
      "\n",
      "USEFUL\n",
      "\n",
      "CERTAIN\n",
      "ADJ that (50) much less certain that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
