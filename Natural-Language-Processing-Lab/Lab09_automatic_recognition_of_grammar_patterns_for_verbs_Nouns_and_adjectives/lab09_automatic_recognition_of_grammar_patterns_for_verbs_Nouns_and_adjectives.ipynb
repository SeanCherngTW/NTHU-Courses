{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akl\n",
    "import math\n",
    "import operator\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "akl = list(akl.akl.keys())\n",
    "PRONS = set([line.strip('\\n') for line in open('prons.txt')])\n",
    "with open('HiFreWords') as f:\n",
    "    HiFreWords = set(f.readline().split('\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_pattern_list(input_pat):\n",
    "    pattern = []\n",
    "    final = []\n",
    "    for i in input_pat:\n",
    "        if i != '':\n",
    "            pattern.append(i)\n",
    "        else:\n",
    "            final.append(pattern.copy())\n",
    "            pattern.clear()\n",
    "\n",
    "    # Last one\n",
    "    final.append(pattern)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus\n",
    "corpus = open('corpus_all.txt', 'r').read().strip('\\n').split('\\n')\n",
    "corpus = create_sentence_pattern_list(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract patterns from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pattern_dict():\n",
    "    pattern_dict = defaultdict(lambda: defaultdict(list))\n",
    "    example_sentences = defaultdict(lambda: defaultdict(list))\n",
    "    for _object in corpus:\n",
    "        sent = _object[0]\n",
    "        for c in _object[1:]:\n",
    "            term, grammar, pattern = c.split('\\t')\n",
    "            pattern_dict[term][grammar] += [pattern]\n",
    "            example_sentences[term][grammar] += [sent.split()]\n",
    "            \n",
    "    return pattern_dict, example_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_dict, example_sentences = build_pattern_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check extracted patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pattern_dict():\n",
    "    print('ABILITY -N')\n",
    "    print('N to v \\t\\t(pd:%d, label:468)\\n' % len(pattern_dict['ABILITY']['N to v']))\n",
    "    \n",
    "    print('VALUE -N')\n",
    "    print('N to v \\t\\t(pd:%3d, label: 16)\\n' % len(pattern_dict['VALUE']['N to v']))\n",
    "    \n",
    "    print('DISCUSS -V')\n",
    "    print('V in n \\t\\t(pd:%3d, label: 47)' % len(pattern_dict['DISCUSS']['V in n']))\n",
    "    print('V n \\t\\t(pd:%3d, label:270)' % len(pattern_dict['DISCUSS']['V n']))\n",
    "    print('V wh to v \\t(pd:%3d, label: 15)\\n' % len(pattern_dict['DISCUSS']['V wh to v']))\n",
    "    \n",
    "    print('FAVOUR -V')\n",
    "    print('V n \\t\\t(pd:%3d, label: 26)' % len(pattern_dict['FAVOUR']['V n']))\n",
    "    print('V by n \\t\\t(pd:%3d, label:  5)\\n' % len(pattern_dict['FAVOUR']['V by n']))\n",
    "    \n",
    "    print('CLASSIFY -V')\n",
    "    print('V into n \\t(pd:%3d, label:  8)' % len(pattern_dict['CLASSIFY']['V into n']))\n",
    "    print('V as n \\t\\t(pd:%3d, label: 12)\\n' % len(pattern_dict['CLASSIFY']['V as n']))\n",
    "\n",
    "    print('USEFUL -ADJ')\n",
    "    print('ADJ to v \\t(pd:%3d, label: 30)' % len(pattern_dict['USEFUL']['ADJ to v']))\n",
    "    print('ADJ for n \\t(pd:%3d, label: 20)\\n' % len(pattern_dict['USEFUL']['ADJ for n']))\n",
    "    \n",
    "    print('CERTAIN -ADJ')\n",
    "    print('ADJ of n \\t(pd:%3d, label: 23)' % len(pattern_dict['CERTAIN']['ADJ of n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABILITY -N\n",
      "N to v \t\t(pd:468, label:468)\n",
      "\n",
      "VALUE -N\n",
      "N to v \t\t(pd: 16, label: 16)\n",
      "\n",
      "DISCUSS -V\n",
      "V in n \t\t(pd: 57, label: 47)\n",
      "V n \t\t(pd:270, label:270)\n",
      "V wh to v \t(pd: 15, label: 15)\n",
      "\n",
      "FAVOUR -V\n",
      "V n \t\t(pd: 26, label: 26)\n",
      "V by n \t\t(pd:  5, label:  5)\n",
      "\n",
      "CLASSIFY -V\n",
      "V into n \t(pd:  8, label:  8)\n",
      "V as n \t\t(pd: 12, label: 12)\n",
      "\n",
      "USEFUL -ADJ\n",
      "ADJ to v \t(pd: 30, label: 30)\n",
      "ADJ for n \t(pd: 20, label: 20)\n",
      "\n",
      "CERTAIN -ADJ\n",
      "ADJ of n \t(pd: 23, label: 23)\n"
     ]
    }
   ],
   "source": [
    "check_pattern_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeScore(word, sent):\n",
    "    global PRONS\n",
    "    global HiFreWords\n",
    "    \n",
    "    word = word.lower()\n",
    "    sent = sent.lower().split()\n",
    "    length = len(sent)\n",
    "    \n",
    "    locationOfWord = -1 if word not in sent else sent.index(word) \n",
    "    hiFreWordsScore = len([w for w in sent if w not in HiFreWords])\n",
    "    pronsScore = len([w for w in sent if w in PRONS])\n",
    "    \n",
    "    return locationOfWord - hiFreWordsScore - pronsScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_pattern(word):\n",
    "    avg = 0.0\n",
    "    stddev = 0.0\n",
    "    k0 = 1\n",
    "    \n",
    "    word = word.upper()\n",
    "    \n",
    "    print(word)\n",
    "\n",
    "    # Total grammar count for the input word\n",
    "    N = len(pattern_dict[word].keys())\n",
    "    \n",
    "    if N == 0:\n",
    "        print('NO RESULT\\n')\n",
    "        return\n",
    "\n",
    "    # Calculate sentence length avg of a grammar\n",
    "    for grammar, sentences in pattern_dict[word].items():\n",
    "        freqi = len(sentences)\n",
    "        avg += freqi\n",
    "    avg /= N\n",
    "\n",
    "    # Calculate stddev\n",
    "    for grammar, sentences in pattern_dict[word].items():\n",
    "        freqi = len(sentences)\n",
    "        stddev += (freqi - avg) ** 2\n",
    "    stddev = math.sqrt(stddev / N - 1)\n",
    "        \n",
    "    if stddev == 0:\n",
    "        print('NO RESULT\\n')\n",
    "        return\n",
    "\n",
    "    best_score = -999.9\n",
    "    best_sentence = ''\n",
    "    \n",
    "    # Filter good grammar\n",
    "    for grammar, sentences in pattern_dict[word].items():\n",
    "        freqi = len(sentences)\n",
    "        strength = (freqi - avg) / stddev\n",
    "        if not strength > k0:\n",
    "            continue\n",
    "\n",
    "        # Find Good Dictionary Example\n",
    "        for sentence in sentences:\n",
    "            score = computeScore(word, sentence)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_sentence = sentence\n",
    "\n",
    "        print('%s (%d) %s' % (grammar, freqi, best_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case():\n",
    "    get_best_pattern('ability')\n",
    "    get_best_pattern('value')\n",
    "    get_best_pattern('discuss')\n",
    "    get_best_pattern('favour')\n",
    "    get_best_pattern('classify')\n",
    "    get_best_pattern('useful')\n",
    "    get_best_pattern('certain')\n",
    "    get_best_pattern('remain')\n",
    "    get_best_pattern('allow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABILITY\n",
      "N to v (468) its bulk and ability to fly\n",
      "\n",
      "VALUE\n",
      "N to v (16) the customer value to do\n",
      "V n (26) the customer value to do\n",
      "\n",
      "DISCUSS\n",
      "V n (270) concerned may have and discuss them\n",
      "\n",
      "FAVOUR\n",
      "V n (26) favour colours\n",
      "\n",
      "CLASSIFY\n",
      "V n (20) can manually classify these content items\n",
      "\n",
      "USEFUL\n",
      "ADJ to v (30) useful to have\n",
      "ADJ for n (20) especially useful for microscopy\n",
      "\n",
      "CERTAIN\n",
      "ADJ that (50) much less certain that\n",
      "\n",
      "REMAIN\n",
      "V n (172) will likely remain north\n",
      "V in n (90) can long remain in existence\n",
      "\n",
      "ALLOW\n",
      "V n (1151) does not allow administrators\n",
      "V n to v (881) does not allow administrators\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following commands were written to file `lab09_automatic_recognition_of_grammar_patterns_for_verbs_Nouns_and_adjectives.py`:\n",
      "import akl\n",
      "import math\n",
      "import operator\n",
      "from pprint import pprint\n",
      "from collections import defaultdict\n",
      "akl = list(akl.akl.keys())\n",
      "PRONS = set([line.strip('\\n') for line in open('prons.txt')])\n",
      "with open('HiFreWords') as f:\n",
      "    HiFreWords = set(f.readline().split('\\t'))\n",
      "def create_sentence_pattern_list(input_pat):\n",
      "    pattern = []\n",
      "    final = []\n",
      "    for i in input_pat:\n",
      "        if i != '':\n",
      "            pattern.append(i)\n",
      "        else:\n",
      "            final.append(pattern.copy())\n",
      "            pattern.clear()\n",
      "\n",
      "    # Last one\n",
      "    final.append(pattern)\n",
      "    return final\n",
      "# Corpus\n",
      "corpus = open('corpus_all.txt', 'r').read().strip('\\n').split('\\n')\n",
      "corpus = create_sentence_pattern_list(corpus)\n",
      "def build_pattern_dict():\n",
      "    pattern_dict = defaultdict(lambda: defaultdict(list))\n",
      "    example_sentences = defaultdict(lambda: defaultdict(list))\n",
      "    for _object in corpus:\n",
      "        sent = _object[0]\n",
      "        for c in _object[1:]:\n",
      "            term, grammar, pattern = c.split('\\t')\n",
      "            pattern_dict[term][grammar] += [pattern]\n",
      "            example_sentences[term][grammar] += [sent.split()]\n",
      "            \n",
      "    return pattern_dict, example_sentences\n",
      "pattern_dict, example_sentences = build_pattern_dict()\n",
      "def check_pattern_dict():\n",
      "    print('ABILITY -N')\n",
      "    print('N to v \\t\\t(pd:%d, label:468)\\n' % len(pattern_dict['ABILITY']['N to v']))\n",
      "    \n",
      "    print('VALUE -N')\n",
      "    print('N to v \\t\\t(pd:%3d, label: 16)\\n' % len(pattern_dict['VALUE']['N to v']))\n",
      "    \n",
      "    print('DISCUSS -V')\n",
      "    print('V in n \\t\\t(pd:%3d, label: 47)' % len(pattern_dict['DISCUSS']['V in n']))\n",
      "    print('V n \\t\\t(pd:%3d, label:270)' % len(pattern_dict['DISCUSS']['V n']))\n",
      "    print('V wh to v \\t(pd:%3d, label: 15)\\n' % len(pattern_dict['DISCUSS']['V wh to v']))\n",
      "    \n",
      "    print('FAVOUR -V')\n",
      "    print('V n \\t\\t(pd:%3d, label: 26)' % len(pattern_dict['FAVOUR']['V n']))\n",
      "    print('V by n \\t\\t(pd:%3d, label:  5)\\n' % len(pattern_dict['FAVOUR']['V by n']))\n",
      "    \n",
      "    print('CLASSIFY -V')\n",
      "    print('V into n \\t(pd:%3d, label:  8)' % len(pattern_dict['CLASSIFY']['V into n']))\n",
      "    print('V as n \\t\\t(pd:%3d, label: 12)\\n' % len(pattern_dict['CLASSIFY']['V as n']))\n",
      "\n",
      "    print('USEFUL -ADJ')\n",
      "    print('ADJ to v \\t(pd:%3d, label: 30)' % len(pattern_dict['USEFUL']['ADJ to v']))\n",
      "    print('ADJ for n \\t(pd:%3d, label: 20)\\n' % len(pattern_dict['USEFUL']['ADJ for n']))\n",
      "    \n",
      "    print('CERTAIN -ADJ')\n",
      "    print('ADJ of n \\t(pd:%3d, label: 23)' % len(pattern_dict['CERTAIN']['ADJ of n']))\n",
      "check_pattern_dict()\n",
      "def computeScore(word, sent):\n",
      "    global PRONS\n",
      "    global HiFreWords\n",
      "    \n",
      "    word = word.lower()\n",
      "    sent = sent.lower().split()\n",
      "    length = len(sent)\n",
      "    \n",
      "    locationOfWord = -1 if word not in sent else sent.index(word) \n",
      "    hiFreWordsScore = len([w for w in sent if w not in HiFreWords])\n",
      "    pronsScore = len([w for w in sent if w in PRONS])\n",
      "    \n",
      "    return locationOfWord - hiFreWordsScore - pronsScore\n",
      "def get_best_pattern(word):\n",
      "    avg = 0.0\n",
      "    stddev = 0.0\n",
      "    k0 = 1\n",
      "    \n",
      "    word = word.upper()\n",
      "    \n",
      "    print(word)\n",
      "\n",
      "    # Total grammar count for the input word\n",
      "    N = len(pattern_dict[word].keys())\n",
      "    \n",
      "    if N == 0:\n",
      "        print('NO RESULT\\n')\n",
      "        return\n",
      "\n",
      "    # Calculate sentence length avg of a grammar\n",
      "    for grammar, sentences in pattern_dict[word].items():\n",
      "        freqi = len(sentences)\n",
      "        avg += freqi\n",
      "    avg /= N\n",
      "\n",
      "    # Calculate stddev\n",
      "    for grammar, sentences in pattern_dict[word].items():\n",
      "        freqi = len(sentences)\n",
      "        stddev += (freqi - avg) ** 2\n",
      "    stddev = math.sqrt(stddev / N - 1)\n",
      "        \n",
      "    if stddev == 0:\n",
      "        print('NO RESULT\\n')\n",
      "        return\n",
      "\n",
      "    best_score = -999.9\n",
      "    best_sentence = ''\n",
      "    \n",
      "    # Filter good grammar\n",
      "    for grammar, sentences in pattern_dict[word].items():\n",
      "        freqi = len(sentences)\n",
      "        strength = (freqi - avg) / stddev\n",
      "        if not strength > k0:\n",
      "            continue\n",
      "\n",
      "        # Find Good Dictionary Example\n",
      "        for sentence in sentences:\n",
      "            score = computeScore(word, sentence)\n",
      "            if score > best_score:\n",
      "                best_score = score\n",
      "                best_sentence = sentence\n",
      "\n",
      "        print('%s (%d) %s' % (grammar, freqi, best_sentence))\n",
      "    print()\n",
      "def test_case():\n",
      "    get_best_pattern('ability')\n",
      "    get_best_pattern('value')\n",
      "    get_best_pattern('discuss')\n",
      "    get_best_pattern('favour')\n",
      "    get_best_pattern('classify')\n",
      "    get_best_pattern('useful')\n",
      "    get_best_pattern('certain')\n",
      "    get_best_pattern('remain')\n",
      "    get_best_pattern('allow')\n",
      "test_case()\n"
     ]
    }
   ],
   "source": [
    "%save lab09_automatic_recognition_of_grammar_patterns_for_verbs_Nouns_and_adjectives.py 17-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
