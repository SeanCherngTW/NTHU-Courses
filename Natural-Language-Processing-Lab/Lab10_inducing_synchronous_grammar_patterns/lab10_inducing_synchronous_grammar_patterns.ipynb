{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import operator\n",
    "from pprint import pprint\n",
    "from orderedset import OrderedSet\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRONS = set([line.strip('\\n') for line in open('prons.txt')])\n",
    "with open('HiFreWords') as f:\n",
    "    HiFreWords = set(f.readline().split('\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_pattern_list(input_pat):\n",
    "    pattern = []\n",
    "    final = []\n",
    "    for i in input_pat:\n",
    "        if i != '':\n",
    "            pattern.append(i)\n",
    "        else:\n",
    "            final.append(pattern.copy())\n",
    "            pattern.clear()\n",
    "\n",
    "    # Last one\n",
    "    final.append(pattern)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "english_corpus = open('corpus.txt', 'r').read().strip('\\n').split('\\n')\n",
    "english_corpus = create_sentence_pattern_list(english_corpus)\n",
    "\n",
    "# English correct sentences\n",
    "english_sent = open('UM-Corpus.en.200k.txt', 'r').read().split('\\n')\n",
    "for ec, es in zip(english_corpus, english_sent):\n",
    "    ec[0] = es\n",
    "    \n",
    "# Chinese\n",
    "chinese_corpus = open('UM-Corpus.ch.200k.tagged.txt', 'r').read().split('\\n')\n",
    "\n",
    "# Align\n",
    "aligns = open('align.final.200k', 'r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract patterns from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_pos(sent1, sent2):\n",
    "    if not isinstance(sent1, list):\n",
    "        sent1 = sent1.split()\n",
    "        \n",
    "    if not isinstance(sent2, list):\n",
    "        sent2 = sent2.split()\n",
    "        \n",
    "    if len(sent1) < len(sent2):\n",
    "        sent1, sent2 = sent2, sent1\n",
    "        \n",
    "    # sent1 is the whole sentence\n",
    "    # sent2 is the sub sentence\n",
    "    \n",
    "    count = 0\n",
    "    n = len(sent2)\n",
    "    for i in range(len(sent1)):\n",
    "        count = 0\n",
    "        for j in range(n):\n",
    "            if sent1[i] == sent2[j]:\n",
    "                count += 1\n",
    "                i += 1\n",
    "                if count == n:\n",
    "                    return (i - n, i)\n",
    "            else:\n",
    "                i -= count\n",
    "                break\n",
    "    return (-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(word, sent):\n",
    "    global PRONS\n",
    "    global HiFreWords\n",
    "    \n",
    "    word = word.lower()\n",
    "    sent = sent.lower().split()\n",
    "    length = len(sent)\n",
    "    \n",
    "    locationOfWord = -1 if word not in sent else sent.index(word) \n",
    "    hiFreWordsScore = len([w for w in sent if w not in HiFreWords])\n",
    "    pronsScore = len([w for w in sent if w in PRONS])\n",
    "    \n",
    "    return locationOfWord - hiFreWordsScore - pronsScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ch_grammar(ch_pat):\n",
    "    ch_grammar = []\n",
    "    \n",
    "    # \"莊稼_N 了_ASP 收割_V 莊稼_N\" -> ['N', 'ASP', 'V', 'N']\n",
    "    for cg in ch_pat.split():\n",
    "        if not ch_grammar:\n",
    "            ch_grammar.append(cg)\n",
    "        else:\n",
    "            if cg != ch_grammar[-1]:\n",
    "                ch_grammar.append(cg)\n",
    "    \n",
    "    ch_grammar = [cg.split('_')[1] for cg in ch_grammar if '_' in cg]\n",
    "#     ch_grammar = [cg for cg in ch_grammar if cg == 'V' or cg == 'P' or cg == 'N']\n",
    "    \n",
    "    if ch_grammar == ['V', 'V']:\n",
    "        ch_grammar = 'V v'\n",
    "    else:\n",
    "        ch_grammar = OrderedSet(ch_grammar)\n",
    "        ch_grammar = ' '.join(ch_grammar).lower().replace('v', 'V')\n",
    "\n",
    "    return ch_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pattern():\n",
    "    count = 0\n",
    "    noisy_channel = defaultdict(lambda: defaultdict(list))\n",
    "    for english, chinese, align in zip(english_corpus, chinese_corpus, aligns):\n",
    "        count += 1\n",
    "        en_sent = english[0].split()\n",
    "        ch_sent = chinese.split()\n",
    "        align = align.split()\n",
    "        en_ch = OrderedDict()\n",
    "        index = 0\n",
    "\n",
    "        try:\n",
    "            for a in align:\n",
    "                en_pos, ch_pos = a.split('-')\n",
    "                en_pos = int(en_pos)\n",
    "                ch_pos = int(ch_pos)\n",
    "                en = en_sent[en_pos]\n",
    "                ch = ch_sent[ch_pos]\n",
    "                en_ch[index, en_pos, en] = ch\n",
    "                index += 1\n",
    "\n",
    "            for _ in english[1:]:\n",
    "                _, en_grammar, en_pat = _.split('\\t')\n",
    "                en_grammar = re.sub('about|in|on|to|for|with', 'p', en_grammar)\n",
    "                start, end = pattern_pos(en_sent, en_pat)\n",
    "                ch_pat = \"\"\n",
    "                for en, ch_term in en_ch.items():\n",
    "                    _, en_pos, en_term = en\n",
    "                    if en_pos >= start and en_pos < end:\n",
    "                        ch_pat += \"%s \" % ch_term\n",
    "                    elif en_pos >= end:\n",
    "                        break\n",
    "                if 'V' in ch_pat:\n",
    "                    ch_grammar = extract_ch_grammar(ch_pat)\n",
    "                    noisy_channel_pattern = \"%s | %s\" % (en_pat, ch_pat)\n",
    "                    noisy_channel[en_grammar][ch_grammar].append(noisy_channel_pattern)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"line %d: %s\" % (count, str(e)))\n",
    "    return noisy_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 166219: list index out of range\n",
      "line 180500: list index out of range\n",
      "line 180503: list index out of range\n",
      "line 186533: list index out of range\n",
      "line 199209: list index out of range\n"
     ]
    }
   ],
   "source": [
    "noisy_channel = extract_pattern()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern(input_pat):\n",
    "    _sum = 0\n",
    "    stddev = 0.0\n",
    "    k0 = 2\n",
    "\n",
    "    N = len(noisy_channel[input_pat])\n",
    "    if N == 0:\n",
    "        return \"NO RESULT\"\n",
    "    \n",
    "    for k, v in noisy_channel[input_pat].items():\n",
    "        _sum += len(v)\n",
    "    avg = _sum / N\n",
    "\n",
    "    print(\"%s (%d)\" % (input_pat, _sum))\n",
    "\n",
    "    for k, v in noisy_channel[input_pat].items():\n",
    "        stddev += (len(v) - avg) ** 2\n",
    "    stddev = math.sqrt(stddev / N - 1)\n",
    "    \n",
    "    final_result = {}\n",
    "    \n",
    "    # Filter good grammar\n",
    "    for grammar, sentences in noisy_channel[input_pat].items():\n",
    "        best_sentences = [(-999.9,''), (-999.9,''), (-999.9,'')]\n",
    "        freqi = len(sentences)\n",
    "        strength = (freqi - avg) / stddev\n",
    "        if not strength > k0:\n",
    "            continue\n",
    "\n",
    "        # Find Good Dictionary Example\n",
    "        for sentence in sentences:\n",
    "            score = compute_score(input_pat, sentence)\n",
    "            if score > best_sentences[0][0]:\n",
    "                best_sentences.pop(0)\n",
    "                best_sentences.append((score, sentence))\n",
    "                best_sentences.sort()\n",
    "\n",
    "        final_result[(grammar, freqi)] = best_sentences\n",
    "\n",
    "    # Print the result\n",
    "    for key in sorted(final_result, key=lambda x: x[1], reverse=True):\n",
    "        values = final_result[key]\n",
    "        print('-> %s (%d)' % (key[0], key[1]))\n",
    "        for value in values:\n",
    "            en, ch = value[1].split(\" | \")\n",
    "            print('     %s %s' % (en, ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V n (121119)\n",
      "-> V n (26660)\n",
      "     authorized me 授權_V 我_N \n",
      "     keeping abreast 與時俱進_V 國際_N \n",
      "     leave any fingerprints 留下_V 指紋_N \n",
      "-> V (7261)\n",
      "     adore everything 崇拜_V \n",
      "     be an aggregate 服務_V \n",
      "     constitute a crime 構成_V \n",
      "-> adV V n (5796)\n",
      "     can help farmers 可以_ADV 幫助_V 糧食_N \n",
      "     did cybernetics 卻_ADV 犧牲_V 控制論_N \n",
      "     get a beer 會_ADV 有_V 啤酒肚_N \n",
      "-> n V (5222)\n",
      "     has clinical importance 糖尿病_N 重要_V \n",
      "     have access 他們_N 訪問_V \n",
      "     have control 你_N 控制_V \n",
      "-> adV V (3923)\n",
      "     get face 去_ADV 面對面_V \n",
      "     inspire a feeling 會_ADV 引起_V \n",
      "     judge intelligence 將_ADV 聰明_V \n",
      "-> V v (2985)\n",
      "     creating alarm 製造_V 驚慌_V \n",
      "     explain everything 說明_V 詳細_V \n",
      "     finds beauty 發現_V 美_V \n",
      "-> V de n (2433)\n",
      "     buy a house 買_V 的_DE 房子_N \n",
      "     give a discount 給_V 的_DE 數量_N \n",
      "     is a function 是_V 的_DE 物件_N \n",
      "-> V det n (2271)\n",
      "     allows everyone 允許_V 每_DET 個人_N \n",
      "     do anything 做到_V 任何_DET 事情_N \n",
      "     is a bird 是_V 一_DET 鳥_N \n",
      "-> V det cl n (1967)\n",
      "     be an American 是_V 一_DET 個_CL 美國人_N \n",
      "     form an arc 形成_V 一_DET 個_CL 光弧_N \n",
      "     is a duality 是_V 一_DET 個_CL 二元性_N \n",
      "-> adV n (1799)\n",
      "     be coal 永遠_ADV 煤炭_N \n",
      "     can detect evidence 可以_ADV 跡象_N \n",
      "     held me 不只_ADV 我_N \n",
      "-> V adV (1783)\n",
      "     do friends 喜歡_V 這麼_ADV \n",
      "     ignoring callers 忽略_V 絕非_ADV \n",
      "     is everything 是_V 都_ADV \n",
      "-> V asp n (1754)\n",
      "     cheated me 欺騙_V 了_ASP 我_N \n",
      "     lost consciousness 失去_V 了_ASP 知覺_N \n",
      "     made friends 結交_V 了_ASP 朋友_N \n",
      "-> V adV n (1753)\n",
      "     are absolutely conditions 是_V 當然_ADV 條件_N \n",
      "     has great attraction 有_V 很_ADV 吸引力_N \n",
      "     is a book 是_V 一_ADV 書_N \n",
      "-> V n de (1535)\n",
      "     draw enemy fire 吸引_V 敵人_N 的_DE \n",
      "     involving investments bases 包括_V 投資_N 的_DE \n",
      "     is added length 加_V 一段_N 地_DE \n",
      "-> V det (1415)\n",
      "     feeds hundreds 救助_V 上千_DET \n",
      "     give any interviews 拒絕_V 任何_DET \n",
      "     give everything 放棄_V 一切_DET \n",
      "-> adV (1363)\n",
      "     applying levels 將_ADV \n",
      "     can keep house 會_ADV \n",
      "     have an account 得_ADV \n",
      "-> p V n (1004)\n",
      "     came form France 從_P 寄來_V 法國_N \n",
      "     has lost confidence 被_P 失去_V 信心_N \n",
      "     laid back its ears 向_P 收_V 兩耳_N \n",
      "-> n adV V (932)\n",
      "     have a look 我們_N 來_ADV 看看_V \n",
      "     have access 您_N 可以_ADV 訪問_V \n",
      "     have great difficulty 學生_N 很_ADV 難_V \n",
      "-> V p n (878)\n",
      "     committed a breach 犯_V 在_P 罪_N \n",
      "     is drinking himself 喝_V 把_P 自己_N \n",
      "     is hand 是_V 用_P 手工_N \n",
      "-> V det cl (862)\n",
      "     are many forms 有_V 很多_DET 種_CL \n",
      "     be an army 成為_V 一_DET 支_CL \n",
      "     is a kind 是_V 一_DET 類_CL \n",
      "------------------------------------------------\n",
      "V p n (27246)\n",
      "-> V n (2785)\n",
      "     is manufactured in China 單挑_V 中國_N \n",
      "     lay for hours 長_V 時間_N \n",
      "     listen for frogs 傾聽_V 蛙鳴_N \n",
      "-> adV V n (1078)\n",
      "     look in the face 再_ADV 看看_V 人_N \n",
      "     are limited in duration 都_ADV 是_V 有效期_N \n",
      "     have decreased in frequency 已經_ADV 下降_V 發生率_N \n",
      "-> n V (922)\n",
      "     are in error 他們_N 錯_V \n",
      "     calling for elections 大選_N 體面_V \n",
      "     had for keeps 他_N 永遠_V \n",
      "-> V p n (804)\n",
      "     buy in China 買_V 在_P 中國_N \n",
      "     live in London 住_V 在_P 倫敦_N \n",
      "     lived in Canada 住_V 在_P 加拿大_N \n",
      "-> adV V (803)\n",
      "     fall in love 不至於_ADV 一見鍾情_V \n",
      "     is in charge 則_ADV 負責_V \n",
      "     is in conference 正在_ADV 開會_V \n",
      "-> V de n (726)\n",
      "     act for me 離開_V 的_DE 我_N \n",
      "     is in front 是_V 的_DE 田埂_N \n",
      "     made in China 生產_V 的_DE 中國_N \n",
      "-> V (707)\n",
      "     is in conformity 符合_V \n",
      "     keep in check 努力_V \n",
      "     know for a certainty 知道_V \n",
      "-> V v (432)\n",
      "     are in approximate balance 接近_V 平衡_V \n",
      "     is in compliance 標準化_V 依從_V \n",
      "     is in full compliance 嚴格_V 遵守_V \n",
      "-> V adV n (314)\n",
      "     go with Jack 去_V 一起_ADV 傑克_N \n",
      "     live in the country 居住_V 極為_ADV 郊外_N \n",
      "     call for me 接_V 來_ADV 我_N \n",
      "-> p V n (298)\n",
      "     is in good shape 在_P 好_V 腿傷_N \n",
      "     may be couched in that kind 用_P 聽慣_V 字眼_N \n",
      "     take for a letter 往_P 寄_V 信_N \n",
      "-> V asp n (286)\n",
      "     applied for a job 申請_V 申請_V 了_ASP 工作_N \n",
      "     are kept on file 保留_V 了_ASP 檔案_N \n",
      "     arrived in congratulation 收到_V 了_ASP 賀信_N \n",
      "-> V n de (275)\n",
      "     know about the background 知道_V 知道_V 焰火_N 之_DE \n",
      "     listen with equal intensity 聆聽_V 別人_N 地_DE 同樣_V \n",
      "     is described in detail 化_V 過程_N 的_DE 具體_V \n",
      "-> V adV (266)\n",
      "     hear about it 聽聽_V 說來_ADV \n",
      "     play for keeps 玩_V 真的_ADV \n",
      "     is in a manner 是_V 可以_ADV \n",
      "-> adV n (230)\n",
      "     burning with love 很_ADV 愛_N \n",
      "     head for his gardens 直_ADV 花園_N \n",
      "     does gather in groups 也_ADV 結群_N \n",
      "-> adV n V (221)\n",
      "     keep in touch 經常_ADV 讀報_N 瞭解_V \n",
      "     waddled in front 常常_ADV 面前_N 站_V \n",
      "     are in good fun 會_ADV 同學_N 說_V \n",
      "-> n adV V (217)\n",
      "     involved in male infertility 男性_N 不_ADV 育_V \n",
      "     are in bond 貨物_N 已_ADV 入_V \n",
      "     had fallen in battle 她_N 萬分_ADV 痛苦_V \n",
      "-> V de (203)\n",
      "     are on loan 是_V 的_DE \n",
      "     are introduced in detail 介紹_V 的_DE \n",
      "     is for a man 是_V 的_DE \n",
      "-> adV V de n (199)\n",
      "     can pull in buyers 能_ADV 拉動_V 的_DE 買家_N \n",
      "     is in charge 一_ADV 是_V 的_DE 部門_N 主管_N \n",
      "     resulting in a deletion 結果_ADV 產生_V 的_DE 缺失_N \n",
      "-> adV V p n (198)\n",
      "     disappear in Asia 憑空_ADV 消失_V 在_P 亞洲_N \n",
      "     is held in England 會_ADV 舉行_V 在_P 英國_N \n",
      "     lived in London 曾_ADV 住_V 在_P 倫敦_N \n",
      "-> V det n (194)\n",
      "     are needed in many countries 需要_V 很多_DET 國家_N \n",
      "     dickered for hours 協議_V 好幾_DET 鐘頭_N \n",
      "     take for me 採取_V 一些_DET 我_N \n",
      "-> n p V (190)\n",
      "     was in despair 他_N 對_P 絕望_V \n",
      "     Egypt in exchange 埃及_N 以_P 換取_V \n",
      "     is in charge 目前_N 在_P 負責_V \n",
      "-> p n V (168)\n",
      "     are in agreement 對_P 看法_N 一致_V \n",
      "     be determined in accordance 按照_P 國家_N 有關_V \n",
      "     dies in a heart attack 在_P 心臟病_N 發作_V \n",
      "-> adV p n (163)\n",
      "     being in heaven 就_ADV 在_P 天堂_N \n",
      "     dig out about Global 一起_ADV 關於_P 全球_N \n",
      "     is in China 正_ADV 在_P 中國_N \n",
      "-> V p (162)\n",
      "     fall in love 喜歡上_V 在_P 喜歡上_V \n",
      "     let in light 讓_V 在_P 輕_V \n",
      "     was in bed 是_V 在_P \n",
      "-> V det cl n (144)\n",
      "     called in a physician 請來_V 一_DET 位_CL 醫生_N \n",
      "     come in a study 來自於_V 一_DET 份_CL 研究人_N \n",
      "     hand in a composition 交_V 一_DET 篇_CL 作文_N \n",
      "-> V loc n (139)\n",
      "     crawl about the deck 爬行_V 上_Loc 甲板_N \n",
      "     happening to himself 發生_V 上_Loc 本人_N \n",
      "     stood in line 站_V 上_Loc 線_N \n",
      "-> p V (134)\n",
      "     asked for money 向_P 討錢_V \n",
      "     is in drop 在_P 在_P 下降_V \n",
      "     ask for advice 向_P 請教_V \n",
      "-> adV p V n (134)\n",
      "     act for him 全權_ADV 代_P 訴訟_V 他_N \n",
      "     have be used in America 已經_ADV 被_P 用來_V 美國_N \n",
      "     is being made for help 正在_ADV 正在_ADV 在_P 呼籲_V 援助_N \n",
      "-> V asp (128)\n",
      "     are being perfected in China 建_V 著_ASP \n",
      "     come in sight 看到_V 了_ASP \n",
      "     headed for home 去_V 回家_V 了_ASP \n",
      "-> n V de (125)\n",
      "     ask for help 他人_N 尋求_V 的_DE 幫助_N \n",
      "     is introduced in detail 主義_N 介紹_V 的_DE 詳細_V \n",
      "     knowledge about foreign land 知識_N 有關_V 外國_N 的_DE \n",
      "-> adV (123)\n",
      "     failing in duty 不_ADV \n",
      "     held for me 會_ADV \n",
      "     is in fact 是否_ADV \n"
     ]
    }
   ],
   "source": [
    "get_pattern('V n')\n",
    "print('------------------------------------------------')\n",
    "get_pattern('V p n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following commands were written to file `lab10_inducing_synchronous_grammar_patterns.py`:\n",
      "import math\n",
      "import operator\n",
      "from pprint import pprint\n",
      "from orderedset import OrderedSet\n",
      "from collections import defaultdict, OrderedDict\n",
      "PRONS = set([line.strip('\\n') for line in open('prons.txt')])\n",
      "with open('HiFreWords') as f:\n",
      "    HiFreWords = set(f.readline().split('\\t'))\n",
      "def create_sentence_pattern_list(input_pat):\n",
      "    pattern = []\n",
      "    final = []\n",
      "    for i in input_pat:\n",
      "        if i != '':\n",
      "            pattern.append(i)\n",
      "        else:\n",
      "            final.append(pattern.copy())\n",
      "            pattern.clear()\n",
      "\n",
      "    # Last one\n",
      "    final.append(pattern)\n",
      "    return final\n",
      "# English\n",
      "english_corpus = open('corpus.txt', 'r').read().strip('\\n').split('\\n')\n",
      "english_corpus = create_sentence_pattern_list(english_corpus)\n",
      "for ec, es in zip(english_corpus, english_sent):\n",
      "    ec[0] = es\n",
      "\n",
      "# English correct sentences\n",
      "english_sent = open('UM-Corpus.en.200k.txt', 'r').read().split('\\n')\n",
      "\n",
      "# Chinese\n",
      "chinese_corpus = open('UM-Corpus.ch.200k.tagged.txt', 'r').read().split('\\n')\n",
      "\n",
      "# Align\n",
      "aligns = open('align.final.200k', 'r').read().split('\\n')\n",
      "def pattern_pos(sent1, sent2):\n",
      "    if not isinstance(sent1, list):\n",
      "        sent1 = sent1.split()\n",
      "        \n",
      "    if not isinstance(sent2, list):\n",
      "        sent2 = sent2.split()\n",
      "        \n",
      "    if len(sent1) < len(sent2):\n",
      "        sent1, sent2 = sent2, sent1\n",
      "        \n",
      "    # sent1 is the whole sentence\n",
      "    # sent2 is the sub sentence\n",
      "    \n",
      "    count = 0\n",
      "    n = len(sent2)\n",
      "    for i in range(len(sent1)):\n",
      "        count = 0\n",
      "        for j in range(n):\n",
      "            if sent1[i] == sent2[j]:\n",
      "                count += 1\n",
      "                i += 1\n",
      "                if count == n:\n",
      "                    return (i - n, i)\n",
      "            else:\n",
      "                i -= count\n",
      "                break\n",
      "    return (-1, -1)\n",
      "def compute_score(word, sent):\n",
      "    global PRONS\n",
      "    global HiFreWords\n",
      "    \n",
      "    word = word.lower()\n",
      "    sent = sent.lower().split()\n",
      "    length = len(sent)\n",
      "    \n",
      "    locationOfWord = -1 if word not in sent else sent.index(word) \n",
      "    hiFreWordsScore = len([w for w in sent if w not in HiFreWords])\n",
      "    pronsScore = len([w for w in sent if w in PRONS])\n",
      "    \n",
      "    return locationOfWord - hiFreWordsScore - pronsScore\n",
      "def extract_ch_grammar(ch_pat):\n",
      "    ch_grammar = []\n",
      "    \n",
      "    # \"莊稼_N 了_ASP 收割_V 莊稼_N\" -> ['N', 'ASP', 'V', 'N']\n",
      "    for cg in ch_pat.split():\n",
      "        if not ch_grammar:\n",
      "            ch_grammar.append(cg)\n",
      "        else:\n",
      "            if cg != ch_grammar[-1]:\n",
      "                ch_grammar.append(cg)\n",
      "    \n",
      "    ch_grammar = [cg.split('_')[1] for cg in ch_grammar if '_' in cg]\n",
      "    ch_grammar = [cg for cg in ch_grammar if cg == 'V' or cg == 'P' or cg == 'N']\n",
      "    \n",
      "    if ch_grammar == ['V', 'V']:\n",
      "        ch_grammar = 'V v'\n",
      "    else:\n",
      "        ch_grammar = OrderedSet(ch_grammar)\n",
      "        ch_grammar = ' '.join(ch_grammar).lower().replace('v', 'V')\n",
      "\n",
      "    return ch_grammar\n",
      "def extract_pattern():\n",
      "    count = 0\n",
      "    noisy_channel = defaultdict(lambda: defaultdict(list))\n",
      "    for english, chinese, align in zip(english_corpus, chinese_corpus, aligns):\n",
      "        count += 1\n",
      "        en_sent = english[0].split()\n",
      "        ch_sent = chinese.split()\n",
      "        align = align.split()\n",
      "        en_ch = OrderedDict()\n",
      "        index = 0\n",
      "\n",
      "        try:\n",
      "            for a in align:\n",
      "                en_pos, ch_pos = a.split('-')\n",
      "                en_pos = int(en_pos)\n",
      "                ch_pos = int(ch_pos)\n",
      "                en = en_sent[en_pos]\n",
      "                ch = ch_sent[ch_pos]\n",
      "                en_ch[index, en_pos, en] = ch\n",
      "                index += 1\n",
      "\n",
      "            for _ in english[1:]:\n",
      "                _, en_grammar, en_pat = _.split('\\t')\n",
      "                start, end = pattern_pos(en_sent, en_pat)\n",
      "                ch_pat = \"\"\n",
      "                for en, ch_term in en_ch.items():\n",
      "                    _, en_pos, en_term = en\n",
      "                    if en_pos >= start and en_pos < end:\n",
      "                        ch_pat += \"%s \" % ch_term\n",
      "                    elif en_pos >= end:\n",
      "                        break\n",
      "                if 'V' in ch_pat:\n",
      "                    ch_grammar = extract_ch_grammar(ch_pat)\n",
      "                    noisy_channel_pattern = \"%s | %s\" % (en_pat, ch_pat)\n",
      "                    noisy_channel[en_grammar][ch_grammar].append(noisy_channel_pattern)\n",
      "\n",
      "        except Exception as e:\n",
      "            print(\"line %d: %s\" % (count, str(e)))\n",
      "    return noisy_channel\n",
      "noisy_channel = extract_pattern()\n",
      "def get_pattern(input_pat):\n",
      "    _sum = 0\n",
      "    stddev = 0.0\n",
      "    k0 = 0.001\n",
      "\n",
      "    N = len(noisy_channel[input_pat])\n",
      "    if N == 0:\n",
      "        return \"NO RESULT\"\n",
      "    \n",
      "    for k, v in noisy_channel[input_pat].items():\n",
      "        _sum += len(v)\n",
      "    avg = _sum / N\n",
      "\n",
      "    print(\"%s (%d)\" % (input_pat, _sum))\n",
      "\n",
      "    for k, v in noisy_channel[input_pat].items():\n",
      "        stddev += (len(v) - avg) ** 2\n",
      "    stddev = math.sqrt(stddev / N - 1)\n",
      "    \n",
      "    final_result = {}\n",
      "    \n",
      "    # Filter good grammar\n",
      "    for grammar, sentences in noisy_channel[input_pat].items():\n",
      "        best_sentences = [(-999.9,''), (-999.9,''), (-999.9,'')]\n",
      "        freqi = len(sentences)\n",
      "        strength = (freqi - avg) / stddev\n",
      "        if not strength > k0:\n",
      "            continue\n",
      "\n",
      "        # Find Good Dictionary Example\n",
      "        for sentence in sentences:\n",
      "            score = compute_score(input_pat, sentence)\n",
      "            if score > best_sentences[0][0]:\n",
      "                best_sentences.pop(0)\n",
      "                best_sentences.append((score, sentence))\n",
      "                best_sentences.sort()\n",
      "\n",
      "        final_result[(grammar, freqi)] = best_sentences\n",
      "\n",
      "    # Print the result\n",
      "    for key in sorted(final_result, key=lambda x: x[1], reverse=True):\n",
      "        values = final_result[key]\n",
      "        print('-> %s (%d)' % (key[0], key[1]))\n",
      "        for value in values:\n",
      "            en, ch = value[1].split(\" | \")\n",
      "            print('     %s %s' % (en, ch))\n",
      "get_pattern('V n')\n"
     ]
    }
   ],
   "source": [
    "%save lab10_inducing_synchronous_grammar_patterns.py 349-359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
