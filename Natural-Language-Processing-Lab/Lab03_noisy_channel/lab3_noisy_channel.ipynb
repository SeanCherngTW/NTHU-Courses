{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Word Probability'''\n",
    "def words(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "count_word = Counter(words(open('big.txt').read()))\n",
    "Nw = sum(count_word.values())\n",
    "Pdist = {word: float(count) / Nw for word, count in count_word.items()}\n",
    "\n",
    "def Pw(word):\n",
    "    return Pdist[word] if word in Pdist else 10 / 10**len(word) / Nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Channel Probability'''\n",
    "count_1edit = defaultdict(lambda: 0)\n",
    "count_c = defaultdict(lambda: 0)\n",
    "for line in open('count_1edit.txt'):\n",
    "    edit, count = line.split('\\t')[0], int(line.split('\\t')[1].replace('\\n', ''))\n",
    "    w, c = edit.split('|')[0], edit.split('|')[1]\n",
    "    count_1edit[(w, c)] += count\n",
    "    count_c[c] += 1\n",
    "\n",
    "r = 10\n",
    "N = dict()\n",
    "for i in range(1, r):\n",
    "    N[i] = (sum(count for count in count_1edit.values() if count == i)) // i\n",
    "N[0] = 26 * 26 * 26 * 26 + 2 * 26 * 26 * 26 + 26 * 26 - sum(N.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smooth(count, r=10):\n",
    "    if count <= r:\n",
    "        return (count + 1) * N[count + 1] / N[count]\n",
    "    else:\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pedit(w, c):\n",
    "    if count_c[c] > 0:\n",
    "        return smooth(count_c[c]) / count_c[c]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Combining channel probability with word probability to score states'''\n",
    "def P(pedit, pw):\n",
    "    return (pedit * pw) * 10 ** 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Next States'''\n",
    "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "def next_states(state):\n",
    "    L, R, edits, pw, pedit = state  # (str, str, list, float, float)\n",
    "    R0, R1 = R[0], R[1:]\n",
    "    if edits == 2:\n",
    "        return [(L + R0, R1, edits, pw, pedit * 0.8)]\n",
    "    noedit = [(L + R0, R1, edits, pw, pedit * 0.8)]\n",
    "    if len(L) > 0:\n",
    "        delete = [(L, R1, edits + 1, Pw(L + R1), P(Pedit(L[-1], L[-1] + R0), Pw(L + R1)))]\n",
    "    else:\n",
    "        delete = [(L, R1, edits + 1, Pw(L + R1), P(Pedit('', R0), Pw(L + R1)))]\n",
    "    insert = [(L + R0 + c, R1, edits + 1, Pw(L + R0 + c + R1), P(Pedit(R0, R0 + c), Pw(L + R0 + c + R1))) for c in letters]\n",
    "    replace = [(L + c, R1, edits + 1, Pw(L + c + R1), P(Pedit(R0, R1), Pw(L + c + R1))) for c in letters]\n",
    "    if len(R1) > 0:\n",
    "        transpose = [(L + R1[0], R0 + R1[1:], edits + 1, Pw(L + R1[0] + R0 + R1[1:]), P(Pedit(R0 + R1[0], R1[0] + R0), Pw(L + R1[0] + R0 + R1[1:])))]\n",
    "    else:\n",
    "        transpose = []\n",
    "    return noedit + delete + insert + replace + transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Correcting'''\n",
    "MAXBEAM = 1000\n",
    "def correction(word):\n",
    "    states = [('', word, 0, Pw(word), 1)]  # initial state\n",
    "    for i in range(len(word)):\n",
    "        states = [newstates for state in states for newstates in next_states(state)]\n",
    "        states = [state for state in states if state[4] > 0]\n",
    "\n",
    "        temp = defaultdict(list)\n",
    "        for state in states:\n",
    "            L, R, edits, pw, pedit = state\n",
    "            temp[L + R].append(state)\n",
    "        states = [min(substates, key=lambda x: x[2]) for wd, substates in temp.items()]\n",
    "\n",
    "        states = sorted(states, key=lambda x: x[4], reverse=True)\n",
    "        states = sorted(states, key=lambda x: x[2])[:MAXBEAM]\n",
    "\n",
    "    states = [state for state in states if state[4] > 0]\n",
    "\n",
    "    return sorted(states, key=lambda x: x[4], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('appearance', '', 2, 0.00012101274219355764, 1404.816691710701),\n",
       " ('appearing', '', 2, 2.061698570705056e-05, 239.3391400692305),\n",
       " ('apparent', '', 2, 3.764840868244015e-05, 194.4622152814735)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"appearant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('running', '', 1, 0.00012549469560813384, 414.85272593381006),\n",
       " ('ruin', '', 2, 4.302675277993161e-05, 347.2539558597741),\n",
       " ('ring', '', 2, 4.9301487560338295e-05, 203.72232077106747)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"runing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('participated', '', 2, 2.6891720487457255e-06, 21.703372241235883),\n",
       " ('participate', '', 1, 3.585562731660967e-06, 11.85293502668029),\n",
       " ('participates', '', 2, 8.963906829152417e-07, 7.234457413745293)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"particpate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('believe', '', 1, 0.00016403949497348924, 677.839721838279),\n",
       " ('believed', '', 2, 7.977877077945652e-05, 643.8667098233311),\n",
       " ('believes', '', 2, 8.963906829152418e-06, 72.34457413745294)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"beleive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('written', '', 2, 0.00010487770990108329, 846.4315174081994),\n",
       " ('writing', '', 2, 6.185095712115169e-05, 319.4736393909922),\n",
       " ('writtung', '', 0, 8.963906829152418e-14, 0.1677721600000001)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('writtung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('happen', '', 2, 8.874267760860894e-05, 1030.1989072545139),\n",
       " ('apply', '', 2, 3.85447993653554e-05, 248.8653350328381),\n",
       " ('hay', '', 2, 3.764840868244015e-05, 243.07776910184185)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `lab3_noisy_channel.py` exists. Overwrite (y/[N])?  y\n",
      "The following commands were written to file `lab3_noisy_channel.py`:\n",
      "import re\n",
      "import math\n",
      "from collections import Counter, defaultdict\n",
      "from pprint import pprint\n",
      "'''Word Probability'''\n",
      "def words(text):\n",
      "    return re.findall(r'\\w+', text.lower())\n",
      "\n",
      "count_word = Counter(words(open('big.txt').read()))\n",
      "Nw = sum(count_word.values())\n",
      "Pdist = {word: float(count) / Nw for word, count in count_word.items()}\n",
      "\n",
      "def Pw(word):\n",
      "    return Pdist[word] if word in Pdist else 10 / 10**len(word) / Nw\n",
      "'''Channel Probability'''\n",
      "count_1edit = defaultdict(lambda: 0)\n",
      "count_c = defaultdict(lambda: 0)\n",
      "for line in open('count_1edit.txt'):\n",
      "    edit, count = line.split('\\t')[0], int(line.split('\\t')[1].replace('\\n', ''))\n",
      "    w, c = edit.split('|')[0], edit.split('|')[1]\n",
      "    count_1edit[(w, c)] += count\n",
      "    count_c[c] += 1\n",
      "\n",
      "r = 10\n",
      "N = dict()\n",
      "for i in range(1, r):\n",
      "    N[i] = (sum(count for count in count_1edit.values() if count == i)) // i\n",
      "N[0] = 26 * 26 * 26 * 26 + 2 * 26 * 26 * 26 + 26 * 26 - sum(N.values())\n",
      "def smooth(count, r=10):\n",
      "    if count <= r:\n",
      "        return (count + 1) * N[count + 1] / N[count]\n",
      "    else:\n",
      "        return count\n",
      "def Pedit(w, c):\n",
      "    if count_c[c] > 0:\n",
      "        return smooth(count_c[c]) / count_c[c]\n",
      "    else:\n",
      "        return 0\n",
      "'''Combining channel probability with word probability to score states'''\n",
      "def P(pedit, pw):\n",
      "    return (pedit * pw) * 10 ** 7\n",
      "'''Next States'''\n",
      "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
      "def next_states(state):\n",
      "    L, R, edits, pw, pedit = state  # (str, str, list, float, float)\n",
      "    R0, R1 = R[0], R[1:]\n",
      "    if edits == 2:\n",
      "        return [(L + R0, R1, edits, pw, pedit * 0.8)]\n",
      "    noedit = [(L + R0, R1, edits, pw, pedit * 0.8)]\n",
      "    if len(L) > 0:\n",
      "        delete = [(L, R1, edits + 1, Pw(L + R1), P(Pedit(L[-1], L[-1] + R0), Pw(L + R1)))]\n",
      "    else:\n",
      "        delete = [(L, R1, edits + 1, Pw(L + R1), P(Pedit('', R0), Pw(L + R1)))]\n",
      "    insert = [(L + R0 + c, R1, edits + 1, Pw(L + R0 + c + R1), P(Pedit(R0, R0 + c), Pw(L + R0 + c + R1))) for c in letters]\n",
      "    replace = [(L + c, R1, edits + 1, Pw(L + c + R1), P(Pedit(R0, R1), Pw(L + c + R1))) for c in letters]\n",
      "    if len(R1) > 0:\n",
      "        transpose = [(L + R1[0], R0 + R1[1:], edits + 1, Pw(L + R1[0] + R0 + R1[1:]), P(Pedit(R0 + R1[0], R1[0] + R0), Pw(L + R1[0] + R0 + R1[1:])))]\n",
      "    else:\n",
      "        transpose = []\n",
      "    return noedit + delete + insert + replace + transpose\n",
      "'''Correcting'''\n",
      "MAXBEAM = 1000\n",
      "def correction(word):\n",
      "    states = [('', word, 0, Pw(word), 1)]  # initial state\n",
      "    for i in range(len(word)):\n",
      "        states = [newstates for state in states for newstates in next_states(state)]\n",
      "        states = [state for state in states if state[4] > 0]\n",
      "\n",
      "        temp = defaultdict(list)\n",
      "        for state in states:\n",
      "            L, R, edits, pw, pedit = state\n",
      "            temp[L + R].append(state)\n",
      "        states = [min(substates, key=lambda x: x[2]) for wd, substates in temp.items()]\n",
      "\n",
      "        states = sorted(states, key=lambda x: x[4], reverse=True)\n",
      "        states = sorted(states, key=lambda x: x[2])[:MAXBEAM]\n",
      "\n",
      "    states = [state for state in states if state[4] > 0]\n",
      "\n",
      "    return sorted(states, key=lambda x: x[4], reverse=True)[:3]\n",
      "correction(\"appearant\")\n"
     ]
    }
   ],
   "source": [
    "%save lab3_noisy_channel.py 2-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
